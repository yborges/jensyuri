<!DOCTYPE html>
<head>
    <meta charset="UTF-8">
    <title>Title</title>
</head>
<body>

<h1>Lab 4</h1>

<h3>Question 1.a.</h3>
<p>There are words in the list that have occured zero times in the text file, like 'iv' and 'ix'.</p>
<h3>Question 1.b.</h3>
<p>The lecturers explanation of stop words: <q>Stop words are meaningless, like I or the or ir.</q> these words are
    removed. It makes sence to put all of these words in the stop words list, except for the word Alice. Because Alice
    is a name and should not be ignored. And also i dont think that 's' and 't' should be ignored, these re just results
    of bad tokenizing. </p>
<h3>Question 1.c.</h3>
<p>No I dont think the top 30 follows Zipf's law, because the first word occurs 2.25 times more than the third word on
    the top 30 (which should be 3 times) and the first word occurs 2.6 times more than the fourth word on the top 30
    (which should be 4 times). You can also see this because the graph is not a straight line in the beginning. </p>
<h3>Question 1.d.</h3>
<p>Heaps law applies. In this case it describes the dictionary size as a function of the input tokens</p>

<h3>Question 2.a.</h3>
<p>The quality of search will be assessed based on the relevance of the returned results.
    The search returns all the document parts, so the precision = relevant parts/total parts.</p>
<h3>Question 2.b.</h3>
<p>Computing the TFIDF matrix takes quite some time, because there has to be calculated a weight of occurance for each
    word in each chapter. </p>
</body>
</html>